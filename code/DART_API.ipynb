{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DART_API\n",
    "\n",
    "The Columbia Basin Research website belonging to the University of Washington School of Aquatic & Fishery Sciences provides access to a variety of datasets on the Columbia River.\n",
    "\n",
    "The Data Access in Real Time (DART) project has several pages set up to make queries. Although there does not appear to be an API, one of the pages http://www.cbr.washington.edu/dart/query/adult_graph_text will create the URL to download data in csv format.\n",
    "\n",
    "This notebook builds a simple API-like interface to download data for this project.\n",
    "\n",
    " - [Dissecting the URL](#Dissecting-the-URL)\n",
    " - [Notebook setup](#Notebook-setup)\n",
    " - [Downloading data](#Downloading-data)\n",
    " - [Output files](#Output-files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dissecting the URL\n",
    "\n",
    "\n",
    "Sockeye daily counts for all locations (Columns) for all days of the year (rows) for 2019\n",
    "\n",
    "This query selected\n",
    " - Output format: CSV\n",
    " - Year: 2019\n",
    " - Project: BON, JDA, MCN, PRD, RIS, RRH, TDA, WAN, WEL\n",
    " - Species: Sockeye\n",
    " - 10 Year: No Selection\n",
    " - River Data: No Selection\n",
    "\n",
    "Note: spaces and newlines inserted for readability\n",
    "http: //www. cbr .washington. edu/dart/cs/php/rpt/mg.php?sc=1&mgconfig=adult\n",
    "\n",
    "    &outputFormat=csv    # csv - locations in columns, csvSingle = single data point per row\n",
    "    &year%5B%5D=2019    \n",
    "    \n",
    "    &loc%5B%5D=BON&loc%5B%5D=JDA&loc%5B%5D=MCN    \n",
    "    &loc%5B%5D=PRD&loc%5B%5D=RIS&loc%5B%5D=RRH    \n",
    "    &loc%5B%5D=TDA&loc%5B%5D=WAN&loc%5B%5D=WEL    \n",
    "    \n",
    "    &ftype%5B%5D=fb     \n",
    "    &data%5B%5D=   \n",
    "    &data%5B%5D=\n",
    "    &startdate=1%2F1\n",
    "    &enddate=12%2F31\n",
    "    &avgyear=0\n",
    "    &sumAttribute=none\n",
    "    &consolidate=1\n",
    "    &zeros=1\n",
    "    &grid=1\n",
    "    &y1min=0\n",
    "    &y1max=\n",
    "    &y2min=\n",
    "    &y2max=\n",
    "    &size=medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: 2018, 3 species, all 9 locations\n",
    "#\n",
    "# http://www.cbr.washington.edu/dart/cs/php/rpt/mg.php?sc=1&mgconfig=adult&outputFormat=csvSingle\n",
    "#    &year%5B%5D=2018&loc%5B%5D=BON&loc%5B%5D=JDA&loc%5B%5D=MCN&loc%5B%5D=PRD&loc%5B%5D=RIS&loc%5B%5D=RRH\n",
    "#    &loc%5B%5D=TDA&loc%5B%5D=WAN&loc%5B%5D=WEL\n",
    "\n",
    "#    &ftype%5B%5D=fc&ftype%5B%5D=fk&ftype%5B%5D=fb&ftype%5B%5D=fp\n",
    "\n",
    "#    &data%5B%5D=&data%5B%5D=&startdate=1%2F1&enddate=12%2F31&avgyear=0&sumAttribute=none&consolidate=1&zeros=1&grid=1&y1min=0&y1max=&y2min=&y2max=&size=medium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "\n",
    "# DART codes for fish species\n",
    "species_dict = {'sockeye':'fb',\n",
    "                'chinook':'fc',\n",
    "                'coho':'fk',\n",
    "                'chum':'fe',\n",
    "                'pink':'fp'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_query(year,species_list,single=True):\n",
    "    '''Construct a query for a particular year and species of fish. All other options are hard coded.'''\n",
    "    \n",
    "    q_base   = 'http://www.cbr.washington.edu/dart/cs/php/rpt/mg.php?sc=1&mgconfig=adult'\n",
    "    \n",
    "    if (single):\n",
    "        q_format = '&outputFormat=csvSingle'\n",
    "    else:\n",
    "        q_format = '&outputFormat=csv'\n",
    "    q_year   = '&year%5B%5D=' + str(year)\n",
    "    q_loc    = '&loc%5B%5D=BON&loc%5B%5D=JDA&loc%5B%5D=MCN&loc%5B%5D=PRD&loc%5B%5D=RIS' + \\\n",
    "                '&loc%5B%5D=RRH&loc%5B%5D=TDA&loc%5B%5D=WAN&loc%5B%5D=WEL'\n",
    "    \n",
    "    q_fish = ''\n",
    "    for species in species_list:\n",
    "        q_fish += '&ftype%5B%5D=' + species_dict[species]\n",
    "    q_tail = '&data%5B%5D=&data%5B%5D=&startdate=1%2F1&enddate=12%2F31&avgyear=0&sumAttribute=none' + \\\n",
    "                '&consolidate=1&zeros=1&grid=1&y1min=0&y1max=&y2min=&y2max=&size=medium'\n",
    "    \n",
    "    final_url = q_base + q_format + q_year + q_loc + q_fish + q_tail\n",
    "    return final_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(CSV_URL):\n",
    "    #https://stackoverflow.com/questions/35371043/use-python-requests-to-download-csv\n",
    "    #CSV_URL = get_sock\n",
    "\n",
    "    with requests.Session() as s:\n",
    "        download = s.get(CSV_URL)\n",
    "\n",
    "        decoded_content = download.content.decode('utf-8')\n",
    "\n",
    "        cr = csv.reader(decoded_content.splitlines(), delimiter=',')\n",
    "        my_list = list(cr)\n",
    "        #for row in my_list:\n",
    "            #print(row)\n",
    "    return my_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example .head() if 'csv' is requested\n",
    "#     mm/dd  2019:JDA:Sock (fish/day)  2019:BON:Sock (fish/day)\n",
    "# 0   1/1    0                         0\n",
    "# 0   1/2    0                         0 \n",
    "\n",
    "\n",
    "# Example .head() if 'csvSingle' is requested         (also known as 'tidy' data)\n",
    "#      year   mm-dd   location  parameter  unit       datatype         value\n",
    "# 0    2019   1-1     JDA       Chin       fish/day   Adult Passage    0\n",
    "# 1    2019   1-2     JDA       Chin       fish/day   Adult Passage    0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_df(data_as_list, single=True):\n",
    "    '''Converts the downloaded data to a pandas DataFrame and reformats the columns.'''\n",
    "    # construct the initial dataframe\n",
    "    df = pd.DataFrame(data_as_list[2:],columns=data_as_list[1])\n",
    "    \n",
    "    if (single):\n",
    "        # construct a date column\n",
    "        df['Date'] = df['year'] + '-' + df['mm-dd']  \n",
    "    else:\n",
    "        # extract year from column location name ' 2019:MCN:Sock (fish/day)' to '2019'\n",
    "        year = df.columns[1].split(':')[0].strip()\n",
    "\n",
    "        # convert column location names from ' 2019:MCN:Sock (fish/day)' to 'MCN'\n",
    "        locations = [df.columns[i].split(':')[1]  for i in range(1,len(df.columns))]\n",
    "\n",
    "        # replace the 'mm/dd' column name with 'Date', then convert '1/1' etc. to '1/1/YYYY'\n",
    "        df.columns = ['Date'] + locations    \n",
    "        df['Date'] = df['Date'] + '/' + year\n",
    "    \n",
    "    # remove the last 7 rows which contain download timestamp and similar info\n",
    "    df = df[:-7]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example - single species**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example: Single species, single year, all 9 Columbia locations, WIDE format\n",
    "\n",
    "# my_url = construct_query(2019,['sockeye'],single=False)\n",
    "# data_as_list = fetch_data(my_url)\n",
    "# df_sockeye_2019 = construct_df(data_as_list,single=False) # works with non-tidy data\n",
    "\n",
    "# df_sockeye_2019.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sockeye_2019.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example - several species**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example: 5 species, single year, all 9 Columbia locations, TIDY format \n",
    "\n",
    "# my_url = construct_query(2019,['sockeye','coho','chinook','chum','pink'],single=True)\n",
    "\n",
    "# data_as_list = fetch_data(my_url)\n",
    "# df = construct_df(data_as_list,single=True)\n",
    "\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['parameter'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Project Data - Fish Counts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009,\n",
       "       2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years_of_interest = np.arange(1999,2021,1)\n",
    "years_of_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_of_interest = ['sockeye','coho','chinook','chum','pink']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = ['year', 'mm-dd', 'location', 'parameter', 'unit', 'datatype', 'value',\n",
    "       'Date']) # giant df accummulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch data for each year\n",
    "for year in years_of_interest:\n",
    "    my_url = construct_query(year,species_of_interest,single=True)\n",
    "    data_as_list = fetch_data(my_url)\n",
    "    df = df.append(construct_df(data_as_list,single=True),ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save fish data to file\n",
    "df.to_csv('../data/DART_csv_files/salmon5_20years.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(292585, 8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
